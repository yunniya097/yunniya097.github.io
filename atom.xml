<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>YUNNI-CODING</title>
  
  <subtitle>Tech-Blog</subtitle>
  <link href="http://yunniya097.github.io/atom.xml" rel="self"/>
  
  <link href="http://yunniya097.github.io/"/>
  <updated>2023-08-03T08:15:43.704Z</updated>
  <id>http://yunniya097.github.io/</id>
  
  <author>
    <name>Yunniya</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension 정리</title>
    <link href="http://yunniya097.github.io/2023/07/31/NLP_BART_Paper/"/>
    <id>http://yunniya097.github.io/2023/07/31/NLP_BART_Paper/</id>
    <published>2023-07-31T06:26:03.000Z</published>
    <updated>2023-08-03T08:15:43.704Z</updated>
    
    <content type="html"><![CDATA[<p>📍 Facebook에서 발표한 논문<br>📍 ACL 2020 accepted</p><p>📄<a href="https://arxiv.org/pdf/1910.13461.pdf">논문 원본</a></p><h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a><strong>ABSTRACT</strong></h2><p>💡 본 논문에서 제안하는 내용</p><ul><li>pre-train을 위한 Seq2Seq model, BART 제안</li><li>BART → standard Transformer-based  Architecture<ul><li>corrupted text를 original text에 mapping denoising autoencoder</li></ul></li></ul><hr><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a><strong>INTRODUCTION</strong></h2><p>💡 <strong>이전 연구</strong></p><p>self-supervised method는 다양한 NLP task에서 주목할만한 성능을 보여줌</p><ul><li><p>그중 단어의 subset이 random masked text를 reconstruct 하도록 학습된 denoising autoencoder(DAE) 방법이 성공적 → MLM의 변형</p></li><li><p>maksed token의 distribution, 예측 순서, 대체 가능한 context 등을 개선해 더 나은 결과를 보여줌</p></li><li><p>self-supervised method 정의</p><p>  : unlabeled data로 좋은 representation을 얻고자하는 학습 방식</p><p>  → <strong>label(y) 없이 input(x) 내에서 target으로 쓰일만 한 것을 정해서 즉 self로 task를 정해서 supervision 방식으로  모델을 학습</strong></p></li><li><p>DAE</p><p>  말그대로 input에 noise를 추가했음에도 디코더의 output은 noise를 추가하지 않은 원본을 복원하도록 하자는 아이디어</p></li></ul><p>💡 <strong>제안 배경</strong></p><p>당시 최근 연구 방법들은 일반적으로 span prediction이나 generation과 같은 특정한 유형의 end task에 초점을 맞춤 → 적용 가능성이 제한적</p><p>ex) BERT는 generation task 적용 불가능, GPT는 bidirectional context 정보 반영 불가능</p><p>💡 <strong>BART</strong></p><p>: standard Transformer-based architecture를 가지며, <strong>B</strong>idirectional과 <strong>A</strong>uto-<strong>R</strong>egressive <strong>T</strong>ransformer를 합친 model</p><p>⇒ BERT의 encoder + GPT의 decoder</p><h2 id="a-BERT-random-token이-mask로-대체되고-문서가-bidirectionl로-encoding됨-누락된-token은-독립적으로-예측되므로-BERT는-generation에-쉽게-사용할-수-x"><a href="#a-BERT-random-token이-mask로-대체되고-문서가-bidirectionl로-encoding됨-누락된-token은-독립적으로-예측되므로-BERT는-generation에-쉽게-사용할-수-x" class="headerlink" title="![(a) BERT: random token이 mask로 대체되고 문서가 bidirectionl로 encoding됨 .누락된 token은 독립적으로 예측되므로 BERT는 generation에 쉽게 사용할 수 x"></a>![(a) BERT: random token이 mask로 대체되고 문서가 bidirectionl로 encoding됨 .누락된 token은 독립적으로 예측되므로 BERT는 generation에 쉽게 사용할 수 x</h2><h2 id="b-GPT-token은-auto-regressive하게-예측되므로-GPT를-generation에-사용-가능-But-단어는-왼쪽-context에만-조건이-적용되므로-bidirectional-상호-작용을-학습할-수-x"><a href="#b-GPT-token은-auto-regressive하게-예측되므로-GPT를-generation에-사용-가능-But-단어는-왼쪽-context에만-조건이-적용되므로-bidirectional-상호-작용을-학습할-수-x" class="headerlink" title="(b) GPT: token은 auto-regressive하게 예측되므로 GPT를 generation에 사용 가능. But 단어는 왼쪽 context에만 조건이 적용되므로 bidirectional 상호 작용을 학습할 수 x"></a>(b) GPT: token은 auto-regressive하게 예측되므로 GPT를 generation에 사용 가능. But 단어는 왼쪽 context에만 조건이 적용되므로 bidirectional 상호 작용을 학습할 수 x</h2><p>(c) BART: encoder에 대한 input이 decoder의 output과 일치할 필요가 없으므로 arbitary noise transformation이 가능. 여기서는 text의 span을 <MASK>로 대체하여 문서가 손상됨 → 손상된 문서(왼쪽)는 bidirectional model로 encoding한 다음 autoregressive decoder를 사용하여 원본 문서(오른쪽)의 가능성을 계산. fine-tuning을 위해 손상되지 않은 문서를 encoder와 decoder에 모두 입력한 후 decoder의 final hidden state의 represenation을 사용.](BART%20Denoising%20Sequence-to-Sequence%20Pre-training%20f%2071d1b4e36ff54c80a818e8e3080efeb3&#x2F;Untitled.png)</p><h2 id="a-BERT-random-token이-mask로-대체되고-문서가-bidirectionl로-encoding됨-누락된-token은-독립적으로-예측되므로-BERT는-generation에-쉽게-사용할-수-x-1"><a href="#a-BERT-random-token이-mask로-대체되고-문서가-bidirectionl로-encoding됨-누락된-token은-독립적으로-예측되므로-BERT는-generation에-쉽게-사용할-수-x-1" class="headerlink" title="(a) BERT: random token이 mask로 대체되고 문서가 bidirectionl로 encoding됨 .누락된 token은 독립적으로 예측되므로 BERT는 generation에 쉽게 사용할 수 x"></a>(a) BERT: random token이 mask로 대체되고 문서가 bidirectionl로 encoding됨 .누락된 token은 독립적으로 예측되므로 BERT는 generation에 쉽게 사용할 수 x</h2><h2 id="b-GPT-token은-auto-regressive하게-예측되므로-GPT를-generation에-사용-가능-But-단어는-왼쪽-context에만-조건이-적용되므로-bidirectional-상호-작용을-학습할-수-x-1"><a href="#b-GPT-token은-auto-regressive하게-예측되므로-GPT를-generation에-사용-가능-But-단어는-왼쪽-context에만-조건이-적용되므로-bidirectional-상호-작용을-학습할-수-x-1" class="headerlink" title="(b) GPT: token은 auto-regressive하게 예측되므로 GPT를 generation에 사용 가능. But 단어는 왼쪽 context에만 조건이 적용되므로 bidirectional 상호 작용을 학습할 수 x"></a>(b) GPT: token은 auto-regressive하게 예측되므로 GPT를 generation에 사용 가능. But 단어는 왼쪽 context에만 조건이 적용되므로 bidirectional 상호 작용을 학습할 수 x</h2><p>(c) BART: encoder에 대한 input이 decoder의 output과 일치할 필요가 없으므로 arbitary noise transformation이 가능. 여기서는 text의 span을 <MASK>로 대체하여 문서가 손상됨 → 손상된 문서(왼쪽)는 bidirectional model로 encoding한 다음 autoregressive decoder를 사용하여 원본 문서(오른쪽)의 가능성을 계산. fine-tuning을 위해 손상되지 않은 문서를 encoder와 decoder에 모두 입력한 후 decoder의 final hidden state의 represenation을 사용.</p><p><strong>2-step of Pre-train</strong></p><ol><li><p>임의의 noising function으로 text를 손상시킴</p></li><li><p>original text를 reconstruct하도록 Seq2Seq를 학습</p></li></ol><p><strong>장점</strong></p><ul><li>noising flexibility → original text에 길이 변경을 포함한 임의의 transformation 적용 가능<ul><li><p>여러 noising approach 실험</p><p>  →  <strong>(1) original text의 순서를 랜덤으로 섞는 방식</strong> + <strong>(2) 임의의 길이 범위(0 포함)의 text를 single mask token으로 대체하는 새로운 in-filling 방식</strong></p><p>  → SOTA를 이루는 approach 발견</p></li><li><p>model이 전체 문장 길이에 대해 더 많이 추론하고, input에 더 긴 범위의 transformation을 수행하게 함 → MLM과 NSP를 generalize</p></li></ul></li><li>text generation을 위한 fine-tuning에 효과적, comprehension task에서도 잘 작동</li><li>fine-tuning에 대한 새로운 사고 방식 확장<ul><li><p>BART 위에 추가적인 transformer layer를 쌓음</p><p>  → 외국어를 noising된 영어로 mapping하고 이를 다시 denoising하는데 사용함으로써 BART가 강력한 번역모델로 동작하게 함</p></li></ul></li></ul><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;📍 Facebook에서 발표한 논문&lt;br&gt;📍 ACL 2020 accepted&lt;/p&gt;
&lt;p&gt;📄&lt;a href=&quot;https://arxiv.org/pdf/1910.13461.pdf&quot;&gt;논문 원본&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;ABSTRACT&quot;&gt;&lt;a h</summary>
      
    
    
    
    <category term="Paper Review" scheme="http://yunniya097.github.io/categories/Paper-Review/"/>
    
    <category term="NLP" scheme="http://yunniya097.github.io/categories/Paper-Review/NLP/"/>
    
    
    <category term="PLM" scheme="http://yunniya097.github.io/tags/PLM/"/>
    
    <category term="NLP" scheme="http://yunniya097.github.io/tags/NLP/"/>
    
    <category term="Paper Review" scheme="http://yunniya097.github.io/tags/Paper-Review/"/>
    
  </entry>
  
  <entry>
    <title>Sound Event Detection: A Tutorial 논문 정리</title>
    <link href="http://yunniya097.github.io/2023/07/26/DSP_SED_Paper/"/>
    <id>http://yunniya097.github.io/2023/07/26/DSP_SED_Paper/</id>
    <published>2023-07-26T05:58:13.000Z</published>
    <updated>2023-07-31T06:26:47.080Z</updated>
    
    <content type="html"><![CDATA[<h2 id="SOUND-EVENTS-INT-OUR-EVERYDAY-ENVIRONMENT"><a href="#SOUND-EVENTS-INT-OUR-EVERYDAY-ENVIRONMENT" class="headerlink" title="SOUND EVENTS INT OUR EVERYDAY ENVIRONMENT"></a>SOUND EVENTS INT OUR EVERYDAY ENVIRONMENT</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;SOUND-EVENTS-INT-OUR-EVERYDAY-ENVIRONMENT&quot;&gt;&lt;a href=&quot;#SOUND-EVENTS-INT-OUR-EVERYDAY-ENVIRONMENT&quot; class=&quot;headerlink&quot; title=&quot;SOUND EVEN</summary>
      
    
    
    
    <category term="Paper Review" scheme="http://yunniya097.github.io/categories/Paper-Review/"/>
    
    <category term="DSP" scheme="http://yunniya097.github.io/categories/Paper-Review/DSP/"/>
    
    
    <category term="Paper Review" scheme="http://yunniya097.github.io/tags/Paper-Review/"/>
    
    <category term="SED" scheme="http://yunniya097.github.io/tags/SED/"/>
    
    <category term="DSP" scheme="http://yunniya097.github.io/tags/DSP/"/>
    
  </entry>
  
  <entry>
    <title>Expectation</title>
    <link href="http://yunniya097.github.io/2023/07/23/Statistics_Expectation/"/>
    <id>http://yunniya097.github.io/2023/07/23/Statistics_Expectation/</id>
    <published>2023-07-23T12:58:13.000Z</published>
    <updated>2023-07-26T05:54:35.506Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Expectation-of-a-Random-Variable"><a href="#Expectation-of-a-Random-Variable" class="headerlink" title="Expectation of a Random Variable"></a>Expectation of a Random Variable</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Expectation-of-a-Random-Variable&quot;&gt;&lt;a href=&quot;#Expectation-of-a-Random-Variable&quot; class=&quot;headerlink&quot; title=&quot;Expectation of a Random Vari</summary>
      
    
    
    
    
    <category term="statistics" scheme="http://yunniya097.github.io/tags/statistics/"/>
    
  </entry>
  
</feed>
